# Smart NID Data Update Workflow
# Checks if new data exists BEFORE downloading to save bandwidth
# NID data updates periodically from the U.S. Army Corps of Engineers

name: Update Dam Data

on:
  schedule:
    # Run weekly on Sunday at 2 AM UTC
    - cron: '0 2 * * 0'

  workflow_dispatch:
    inputs:
      force_update:
        description: 'Force update even if no new data detected'
        required: false
        default: 'false'
        type: boolean

env:
  NODE_VERSION: '20'

jobs:
  # Job 1: Lightweight check if update is needed (HEAD request, no download)
  check-for-update:
    runs-on: ubuntu-latest
    outputs:
      has_update: ${{ steps.check.outputs.has_update }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Check for new NID data
        id: check
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          set +e
          npx tsx scripts/check-nid-update.ts
          EXIT_CODE=$?
          set -e

          echo "Check script exit code: $EXIT_CODE"

          if [ $EXIT_CODE -eq 1 ]; then
            echo "üìä Update available"
            echo "has_update=true" >> $GITHUB_OUTPUT
          elif [ $EXIT_CODE -eq 0 ]; then
            echo "‚úÖ No update needed"
            echo "has_update=false" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è Error checking for update (exit code: $EXIT_CODE)"
            echo "has_update=false" >> $GITHUB_OUTPUT
          fi

  # Job 2: Download and ingest data (only if update needed or forced)
  update-data:
    needs: check-for-update
    if: needs.check-for-update.outputs.has_update == 'true' || inputs.force_update == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Download latest NID data
        id: download
        run: |
          mkdir -p data
          echo "Downloading latest NID data..."
          curl -L -o data/nation.csv "https://nid.sec.usace.army.mil/api/nation/csv"

          if [ -f "data/nation.csv" ]; then
            FILE_SIZE=$(wc -c < data/nation.csv)
            RECORD_COUNT=$(wc -l < data/nation.csv)
            echo "file_size=$FILE_SIZE" >> $GITHUB_OUTPUT
            echo "record_count=$RECORD_COUNT" >> $GITHUB_OUTPUT
            echo "has_data=true" >> $GITHUB_OUTPUT
            echo "Downloaded: $FILE_SIZE bytes, ~$RECORD_COUNT lines"
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
          fi

      - name: Run data ingestion
        if: steps.download.outputs.has_data == 'true'
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: npx tsx scripts/ingest-data.ts

      - name: Update county counts
        if: steps.download.outputs.has_data == 'true'
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: npx tsx scripts/update-county-counts.ts

      - name: Validate ingested data
        if: steps.download.outputs.has_data == 'true'
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          node -e "
            const { createClient } = require('@supabase/supabase-js');
            const supabase = createClient(process.env.NEXT_PUBLIC_SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
            (async () => {
              const { count } = await supabase.from('dams').select('*', { count: 'exact', head: true });
              console.log('Dam count after ingestion:', count);
              if (!count || count < 50000) {
                console.error('VALIDATION FAILED: Expected 50K+ dams, got ' + count);
                process.exit(1);
              }
              console.log('Validation passed.');
            })();
          "

      - name: Update metadata
        if: steps.download.outputs.has_data == 'true'
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          LAST_MOD=$(curl -sI "https://nid.sec.usace.army.mil/api/nation/csv" | grep -i "last-modified" | cut -d: -f2- | xargs || echo "")

          node -e "
            const { createClient } = require('@supabase/supabase-js');
            const supabase = createClient(process.env.NEXT_PUBLIC_SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE_KEY);
            supabase.from('data_metadata').upsert({
              id: 1,
              source_name: 'National Inventory of Dams',
              source_url: 'https://nid.sec.usace.army.mil/api/nation/csv',
              record_count: ${{ steps.download.outputs.record_count }},
              file_size: ${{ steps.download.outputs.file_size }},
              last_modified_header: '$LAST_MOD' || null,
              last_updated: new Date().toISOString(),
              last_checked_at: new Date().toISOString(),
            }).then(({ error }) => {
              if (error) console.error('Metadata update failed:', error.message);
              else console.log('Metadata updated successfully');
            });
          "

      - name: Commit data if changed
        if: steps.download.outputs.has_data == 'true'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          if git diff --quiet data/; then
            echo "No changes to commit"
          else
            git add data/
            git commit -m "chore: update NID dam data (${{ steps.download.outputs.record_count }} records)"
            git push
          fi

      - name: Create summary
        run: |
          echo "## NID Data Update Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Records**: ~${{ steps.download.outputs.record_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- **File size**: ${{ steps.download.outputs.file_size }} bytes" >> $GITHUB_STEP_SUMMARY
          echo "- **Forced**: ${{ inputs.force_update || 'false' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Data source: [National Inventory of Dams](https://nid.sec.usace.army.mil/)" >> $GITHUB_STEP_SUMMARY

  # Job 3: Notify on failure
  notify-failure:
    runs-on: ubuntu-latest
    needs: [check-for-update, update-data]
    if: failure()

    steps:
      - name: Create issue on failure
        uses: actions/github-script@v7
        with:
          script: |
            const title = `‚ö†Ô∏è NID Data Update Failed - ${new Date().toISOString().split('T')[0]}`;

            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'automation-failure'
            });

            if (issues.data.length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title,
                body: `Automated NID data update workflow failed.\n\n**Run**: ${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}\n\nPlease check the workflow logs.`,
                labels: ['automation-failure']
              });
            }
